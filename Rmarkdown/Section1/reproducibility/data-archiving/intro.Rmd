### Introduction {-}

Many people, companies, and organizations seem to struggle with data archiving. Data gets pulled from whatever system, then gets processed, generates output, and the output is then delivered. And somehwere along the way after generating output the data get saved. The process seems simple enough! 

Most people just write out the data to the Data/ folder. However, in large projects the data folder can quickly get messy. All the sudden there are files like summary_data_v1.xlsx, data_v2_20180912.csv, or there are the folders in which the data just get overwritten over each time. These folders may look clean, but the output generated from these data will never be able to be replicated again.

The folder structure where the date get written over each time clearly has issues, but so does the folder with the data title data_v2_20180912.csv. Even is these data are data_20180912.csv, this still creates issues! If those data need to be re-generated, and then they're used as an input downstream, then the downstream code has to be changed as well. The likelihood that the project is in it's final stages, or very behind, or someone doesn't communicate that the data has changed is high! So then data_20180912.csv never gets changed to data_20180922.csv, which then causes everyone to freak out because the deliverable is due, but the issue still isn't fixed, but it really is, we just forgot to change the path! AHHH!!!

To make things even worse, when we generate the final deliverable did it come from the data versioned data_20180917 or from data_20180912? Although it's often the case that the most recently generated data is used to create the final output, it's not always the case. 

There has to be a better system ... and there is!

#### Suggested folder structure {-}

I'm sure there are multiple ways for solve this problem, but I've been very successful using one in particular.

This is the file structure that I use.

```
Data/
  Processed/
    Current/
    Archive/
  Raw/
```

In the data folder there are two folders: `Processed` and `Raw`. Raw contains the raw data and processed contains the data that have been validated and managed.

Within the processed file there are two folders: `Current` and `Archive`. The `Current` folder contains the most recently processed files. The files in this folder DO NOT have time specific names. There aren't any data like summary_data_20180912.csv. Instead there's just a file that says summary data.csv. 

However, in the `Archive` folder, there are timestamped zipfiles containing all the data that were generated on a single day. All the zipped files in this folder are named systematically such that it's easy to tell when the data were create and maybe why!

Example: 

```
Data/
  Processed/
    Current/
      data.csv
      summary_data.csv
      summary_stats.csv
      log.txt
    Archive/
      20180912.zip
      20180917.zip
      20180922.zip
  Raw/
```

If we were to open up 20180912.zip it would look like this:

```
data.csv
summary_data.csv
summary_stats.csv
log.txt
```
Wowza, this structure solves a lot of problems! We don't have to worry about filenames downstream having to get updated because they're pointed at the `Current` folder. At the same time, we have a record of all the data we created, that way if we delivered output generated from data 20180717, and the client/partner has a question about the data, we can easily open it up and access it.



